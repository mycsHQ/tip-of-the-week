# Tips to work with logs or big files

### 1. grep

Useful to filter result
http://tldp.org/LDP/Bash-Beginners-Guide/html/sect_04_02.html
```
grep uuid 180328-mx-masterfeed-uk.csv
```

### 2. cat, | more, | less

https://www.tecmint.com/13-basic-cat-command-examples-in-linux/

```
cat ~/.ssh/id_rsa.pub
cat 180328-mx-masterfeed-uk.csv | less
```

### 3. ">", ">>"
Redirect the output to a file:
```
someCommand > someFile.txt
```
Or if you want to append data:
```
someCommand >> someFile.txt
```
If you want also stderr use this:
```
someCommand &> someFile.txt
someCommand &>> someFile.txt
```

### 4. head, tail
First N lines of the file
```
head -n 1 180328-mx-masterfeed-uk.csv
```
Last N lines of the file
```
tail -n 1 180328-mx-masterfeed-uk.csv
```

### 5. Using the pipe | and &&
a Unix redirection operator, you can tell grep to search for more than one string
```
ls -l | grep test
```
```
head -n 1 180328-mx-masterfeed-uk.csv > test.csv & grep QHCPbEY7Z 180328-mx-masterfeed-uk.csv >> test.csv
```

### 6. Download logs from CloudFrontDistribution
https://gist.github.com/shapeshed/e25bdf3b1116899fa8c47c16db9aa8e0
```
#!/bin/bash
for i in $( ls ); do
    aws s3 cp $i
done
```
```
aws s3 ls s3://routing-dev-frontendlogslogsbucket-hojrl8i5ien5/frontendDistribution/E299Q18MWX6BIG.2018-03-29 | awk '{print $4}'
```

### 7. awslogs
is a simple command line tool for querying groups, streams and events from Amazon CloudWatch logs
https://github.com/jorgebastida/awslogs